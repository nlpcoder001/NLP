{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP The/DT big/JJ cat/NN)\n",
      "  ate/VBD\n",
      "  (NP the/DT little/JJ mouse/NN)\n",
      "  who/WP\n",
      "  was/VBD\n",
      "  after/IN\n",
      "  (NP fresh/JJ cheese/NN))\n",
      "(NP The/DT big/JJ cat/NN)\n",
      "(NP the/DT little/JJ mouse/NN)\n",
      "(NP fresh/JJ cheese/NN)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "# Your sentence\n",
    "sentence = \"The big cat ate the little mouse who was after fresh cheese\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokenized_sentence = nltk.word_tokenize(sentence)\n",
    "\n",
    "# Tag the sentence using POS tagger\n",
    "tagged_sentence = nltk.pos_tag(tokenized_sentence)\n",
    "\n",
    "# Define your grammar using regular expressions\n",
    "grammar = ('''\n",
    "    NP: {<DT>?<JJ>*<NN>} # NP\n",
    "    ''')\n",
    "\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "tree = chunk_parser.parse(tagged_sentence)\n",
    "\n",
    "# Print the result\n",
    "for subtree in tree.subtrees():\n",
    "    print(subtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Define chunk grammar for noun phrases and verb groups\n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT>?<JJ>*<NN.*>+}  # Chunk sequences of DT, JJ, NN\n",
    "    VG: {<VB.*><NP|PP|RB|DT>*}  # Chunk sequences of VB and NP, PP, RB, DT\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def categorize(sentence):\n",
    "    # Tokenize and POS tag a sentence\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "    NG=[]\n",
    "    VG=[]\n",
    "    for i in tagged_tokens:\n",
    "        if i[1]==\"DT\" or i[1]==\"JJ\" or i[1]==\"NN\":\n",
    "            NG.append(i[0])\n",
    "        elif i[1]==\"VBZ\" or i[1]==\"VBD\" or i[1]==\"PP\" or i[1]==\"RB\":\n",
    "            VG.append(i[0])\n",
    "    print(f\"Given Sentence: {sentence}\")\n",
    "    print(f\"Words from Given Sentence in Noun Group: {NG}\")\n",
    "    print(f\"Words from Given Sentence in Verb Group: {VG}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given Sentence: The big cat ate the little mouse who was after fresh cheese\n",
      "Words from Given Sentence in Noun Group: ['The', 'big', 'cat', 'the', 'little', 'mouse', 'fresh', 'cheese']\n",
      "Words from Given Sentence in Verb Group: ['ate', 'was']\n"
     ]
    }
   ],
   "source": [
    "categorize(\"The big cat ate the little mouse who was after fresh cheese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "NG=[]\n",
    "VG=[]\n",
    "for i in tagged_tokens:\n",
    "    if i[1]==\"DT\" or i[1]==\"JJ\" or i[1]==\"NN\":\n",
    "        NG.append(i[0])\n",
    "    elif i[1]==\"VBZ\" or i[1]==\"NP\" or i[1]==\"PP\" or i[1]==\"RB\":\n",
    "        VG.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jumps']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
